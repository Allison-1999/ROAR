wandb_version: 1

_current_progress_remaining:
  desc: null
  value: 0.9746704743860846
_custom_logger:
  desc: null
  value: 'False'
_episode_num:
  desc: null
  value: 0
_last_episode_starts:
  desc: null
  value: '[ True]'
_last_obs:
  desc: null
  value: "[[[[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
    \ ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0.\
    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0.\
    \ 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
    \    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
    \ 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0.\
    \ 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n   \
    \ [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0.\
    \ 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n\
    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0.\
    \ 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0.\
    \ 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0. ... 0. 0. 0.]\n\
    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\
    \n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
    \ 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
    \    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ...\
    \ 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n\
    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]\n\n\n  [[[0. 0. 0.\
    \ ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n  \
    \  ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0.\
    \ ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n\
    \    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0.\
    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]\n\n   [[0. 0. 0. ... 0. 0. 0.]\n\
    \    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    ...\n    [0. 0.\
    \ 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]\n    [0. 0. 0. ... 0. 0. 0.]]]]]"
_last_original_obs:
  desc: null
  value: None
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x000001A90C121848>
_n_updates:
  desc: null
  value: 20
_num_timesteps_at_start:
  desc: null
  value: 34315
_total_timesteps:
  desc: null
  value: 1034315
_vec_normalize_env:
  desc: null
  value: None
_wandb:
  desc: null
  value:
    cli_version: 0.12.16
    code_path: code/ROAR_gym/e2eModel.py
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.7.12
    start_time: 1651990465
    t:
      1:
      - 1
      - 41
      - 55
      3:
      - 13
      - 14
      - 16
      - 34
      4: 3.7.12
      5: 0.12.16
      8:
      - 3
      - 5
action_noise:
  desc: null
  value: None
action_space:
  desc: null
  value: Box([-2.5 -5.   1.  -2.5 -5.   1.  -2.5 -5.   1.  -2.5 -5.   1. ], [-0.5  5.   3.  -0.5  5.   3.  -0.5  5.   3.  -0.5  5.   3.
    ], (12,), float32)
algo:
  desc: null
  value: PPO
batch_size:
  desc: null
  value: 64
clip_range:
  desc: null
  value: <function constant_fn.<locals>.func at 0x000001A8594E5C18>
clip_range_vf:
  desc: null
  value: None
device:
  desc: null
  value: cpu
ent_coef:
  desc: null
  value: 0
env:
  desc: null
  value: <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001A841814848>
env_name:
  desc: null
  value: roar-e2e-ppo-v0
ep_info_buffer:
  desc: null
  value: 'deque([{''r'': -528.75, ''l'': 89, ''t'': 2183.22724}, {''r'': -500.5, ''l'':
    81, ''t'': 2193.772217}, {''r'': -501.5, ''l'': 81, ''t'': 2278.975465}, {''r'':
    -461.25, ''l'': 70, ''t'': 2288.007459}, {''r'': -523.75, ''l'': 88, ''t'': 2298.965042},
    {''r'': -435.75, ''l'': 62, ''t'': 2307.116458}, {''r'': -468.25, ''l'': 72, ''t'':
    2316.473886}, {''r'': -667.0, ''l'': 128, ''t'': 2332.669133}, {''r'': -509.5,
    ''l'': 83, ''t'': 2343.573204}, {''r'': -509.5, ''l'': 83, ''t'': 2354.075483},
    {''r'': -582.25, ''l'': 104, ''t'': 2367.13785}, {''r'': -447.0, ''l'': 66, ''t'':
    2376.073622}, {''r'': -743.0, ''l'': 151, ''t'': 2395.277082}, {''r'': -659.0,
    ''l'': 126, ''t'': 2410.886319}, {''r'': -394.25, ''l'': 107, ''t'': 2424.386265},
    {''r'': -713.5, ''l'': 142, ''t'': 2442.205247}, {''r'': -305.5, ''l'': 82, ''t'':
    2452.870484}, {''r'': -465.25, ''l'': 71, ''t'': 2462.488237}, {''r'': -536.75,
    ''l'': 91, ''t'': 2474.038613}, {''r'': -446.0, ''l'': 66, ''t'': 2482.931249},
    {''r'': -504.5, ''l'': 82, ''t'': 2493.932827}, {''r'': -569.0, ''l'': 100, ''t'':
    2506.703166}, {''r'': -553.0, ''l'': 96, ''t'': 2518.845388}, {''r'': -493.5,
    ''l'': 79, ''t'': 2529.128018}, {''r'': -539.75, ''l'': 92, ''t'': 2540.947031},
    {''r'': -473.25, ''l'': 73, ''t'': 2550.551163}, {''r'': -515.5, ''l'': 85, ''t'':
    2561.821096}, {''r'': -561.0, ''l'': 98, ''t'': 2574.41739}, {''r'': -520.75,
    ''l'': 87, ''t'': 2585.772798}, {''r'': -497.5, ''l'': 80, ''t'': 2596.55825},
    {''r'': -749.75, ''l'': 152, ''t'': 2615.716088}, {''r'': -354.0, ''l'': 96, ''t'':
    2628.263789}, {''r'': -574.0, ''l'': 101, ''t'': 2641.437396}, {''r'': -738.75,
    ''l'': 149, ''t'': 2660.447495}, {''r'': -469.25, ''l'': 72, ''t'': 2670.037799},
    {''r'': -325.75, ''l'': 88, ''t'': 2681.976226}, {''r'': -301.5, ''l'': 81, ''t'':
    2692.67536}, {''r'': -346.0, ''l'': 94, ''t'': 2704.783433}, {''r'': -456.0, ''l'':
    68, ''t'': 2713.976779}, {''r'': -578.25, ''l'': 103, ''t'': 2727.235261}, {''r'':
    -551.0, ''l'': 96, ''t'': 2739.849205}, {''r'': -454.0, ''l'': 68, ''t'': 2748.70834},
    {''r'': -477.25, ''l'': 74, ''t'': 2758.392036}, {''r'': -465.25, ''l'': 71, ''t'':
    2767.695968}, {''r'': -253.0, ''l'': 67, ''t'': 2776.714006}, {''r'': -435.0,
    ''l'': 63, ''t'': 2785.288556}, {''r'': -342.0, ''l'': 93, ''t'': 2797.354524},
    {''r'': -744.75, ''l'': 151, ''t'': 2816.975788}, {''r'': -423.75, ''l'': 59,
    ''t'': 2824.98525}, {''r'': -437.0, ''l'': 63, ''t'': 2833.409212}, {''r'': -317.5,
    ''l'': 85, ''t'': 2844.705682}, {''r'': -450.0, ''l'': 67, ''t'': 2853.484568},
    {''r'': -589.25, ''l'': 106, ''t'': 2867.536126}, {''r'': -566.0, ''l'': 99, ''t'':
    2880.771442}, {''r'': -461.25, ''l'': 70, ''t'': 2890.171807}, {''r'': -494.5,
    ''l'': 80, ''t'': 2900.87903}, {''r'': -507.5, ''l'': 83, ''t'': 2912.031872},
    {''r'': -531.75, ''l'': 90, ''t'': 2923.719686}, {''r'': -427.75, ''l'': 60, ''t'':
    2931.791074}, {''r'': -628.5, ''l'': 117, ''t'': 2946.854599}, {''r'': -422.75,
    ''l'': 59, ''t'': 2954.763139}, {''r'': -458.0, ''l'': 69, ''t'': 2963.937724},
    {''r'': -569.0, ''l'': 100, ''t'': 2977.493226}, {''r'': -491.5, ''l'': 79, ''t'':
    2987.713591}, {''r'': -462.25, ''l'': 71, ''t'': 2997.155107}, {''r'': -505.5,
    ''l'': 82, ''t'': 3008.380426}, {''r'': -417.75, ''l'': 58, ''t'': 3016.080088},
    {''r'': -212.75, ''l'': 56, ''t'': 3023.693192}, {''r'': -562.0, ''l'': 98, ''t'':
    3036.526028}, {''r'': -450.0, ''l'': 67, ''t'': 3045.475892}, {''r'': -534.75,
    ''l'': 91, ''t'': 3057.483063}, {''r'': -269.25, ''l'': 72, ''t'': 3067.322178},
    {''r'': -224.75, ''l'': 59, ''t'': 3075.466063}, {''r'': -576.25, ''l'': 103,
    ''t'': 3088.926925}, {''r'': -618.5, ''l'': 114, ''t'': 3104.37608}, {''r'': -695.25,
    ''l'': 136, ''t'': 3121.86135}, {''r'': -441.0, ''l'': 64, ''t'': 3130.33276},
    {''r'': -237.0, ''l'': 63, ''t'': 3138.768524}, {''r'': -485.25, ''l'': 76, ''t'':
    3148.784702}, {''r'': -392.5, ''l'': 50, ''t'': 3155.705377}, {''r'': -618.5,
    ''l'': 114, ''t'': 3171.085482}, {''r'': -412.75, ''l'': 56, ''t'': 3178.643672},
    {''r'': -577.25, ''l'': 103, ''t'': 3192.023938}, {''r'': -616.5, ''l'': 114,
    ''t'': 3207.309929}, {''r'': -540.75, ''l'': 92, ''t'': 3219.26562}, {''r'': -496.25,
    ''l'': 79, ''t'': 3229.580259}, {''r'': -273.25, ''l'': 73, ''t'': 3239.527527},
    {''r'': -632.75, ''l'': 119, ''t'': 3255.431475}, {''r'': -492.25, ''l'': 78,
    ''t'': 3266.090657}, {''r'': -592.5, ''l'': 165, ''t'': 3287.898526}, {''r'':
    -285.25, ''l'': 76, ''t'': 3297.806956}, {''r'': -486.25, ''l'': 77, ''t'': 3307.697387},
    {''r'': -560.0, ''l'': 98, ''t'': 21.20266}, {''r'': -460.0, ''l'': 69, ''t'':
    31.328862}, {''r'': -418.75, ''l'': 58, ''t'': 39.740796}, {''r'': -657.75, ''l'':
    125, ''t'': 56.228121}, {''r'': -476.25, ''l'': 74, ''t'': 66.160737}, {''r'':
    -456.0, ''l'': 68, ''t'': 80.044044}, {''r'': -414.5, ''l'': 113, ''t'': 110.137575},
    {''r'': -491.25, ''l'': 78, ''t'': 131.936149}], maxlen=100)'
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
eval_env:
  desc: null
  value: None
gae_lambda:
  desc: null
  value: 0.95
gamma:
  desc: null
  value: 0.99
learning_rate:
  desc: null
  value: 1.0e-05
lr_schedule:
  desc: null
  value: <function constant_fn.<locals>.func at 0x000001A8594E5EE8>
max_grad_norm:
  desc: null
  value: 0.5
n_envs:
  desc: null
  value: 1
n_epochs:
  desc: null
  value: 10
n_steps:
  desc: null
  value: 8192
normalize_advantage:
  desc: null
  value: 'True'
num_timesteps:
  desc: null
  value: 34315
observation_space:
  desc: null
  value: "Box([[[[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10.\
    \ -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n \
    \  [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ...\
    \ -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n \
    \ [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]]]\n\n\n [[[-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\n  [[-10. -10. -10. ... -10.\
    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
    \ -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]]\n\n\n [[[-10.\
    \ -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10.\
    \ -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]]\n\
    \n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n\
    \   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10.\
    \ -10.]]\n\n  [[-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10. ... -10.\
    \ -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   ...\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]\n   [-10. -10. -10. ... -10. -10. -10.]\n   [-10. -10. -10.\
    \ ... -10. -10. -10.]]]], [[[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]]]\n\n\n [[[1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1. 1. 1. ... 1. 1. 1.]\n \
    \  [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   ...\n   [1. 1. 1. ...\
    \ 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]]\n\n  [[1.\
    \ 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n\
    \   ...\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1. ... 1. 1. 1.]\n   [1. 1. 1.\
    \ ... 1. 1. 1.]]]], (4, 3, 84, 84), float32)"
policy:
  desc: null
  value: "ActorCriticCnnPolicy(\n  (features_extractor): Atari_PPO_Adapted_CNN(\n\
    \    (network): Sequential(\n      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4,\
    \ 4))\n      (1): ReLU()\n      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2,\
    \ 2))\n      (3): ReLU()\n      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,\
    \ 1))\n      (5): ReLU()\n      (6): Flatten(start_dim=1, end_dim=-1)\n      (7):\
    \ Linear(in_features=3136, out_features=256, bias=True)\n    )\n  )\n  (mlp_extractor):\
    \ MlpExtractor(\n    (shared_net): Sequential()\n    (policy_net): Sequential(\n\
    \      (0): Linear(in_features=256, out_features=64, bias=True)\n      (1): Tanh()\n\
    \      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n\
    \    )\n    (value_net): Sequential(\n      (0): Linear(in_features=256, out_features=64,\
    \ bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64,\
    \ bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64,\
    \ out_features=12, bias=True)\n  (value_net): Linear(in_features=64, out_features=1,\
    \ bias=True)\n)"
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.ActorCriticCnnPolicy'>
policy_kwargs:
  desc: null
  value: '{''features_extractor_class'': <class ''ppo_util.Atari_PPO_Adapted_CNN''>,
    ''features_extractor_kwargs'': {''features_dim'': 256}}'
policy_type:
  desc: null
  value: CnnPolicy
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x000001A8593EBC08>
sde_sample_freq:
  desc: null
  value: -1
seed:
  desc: null
  value: 1
start_time:
  desc: null
  value: 1651786978.8466144
target_kl:
  desc: null
  value: None
tensorboard_log:
  desc: null
  value: runs/Run 5
training_kwargs:
  desc: null
  value:
    batch_size: 64
    device: cpu
    ent_coef: 0.0
    gamma: 0.99
    learning_rate: 1.0e-05
    n_steps: 8192
    seed: 1
    verbose: 1
use_sde:
  desc: null
  value: 'False'
verbose:
  desc: null
  value: 1
vf_coef:
  desc: null
  value: 0.5
